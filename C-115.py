# -*- coding: utf-8 -*-
"""C-115

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wetGXvkyCkhhUUk4k5Z4qDdVAjZoXkaq

## Load the Dataset
"""

#Load the dataset from given directory
!git clone https://github.com/procodingclass/PRO-C114-Text-Sentiment-Dataset

"""## Pandas:
**Pandas** is an open-source library built on top of Numpy and Matplotlib. It provides high-performance, easy-to-use data structures and data analysis tools.

A DataFrame is a two-dimensional data structure, i.e., data is aligned in a tabular fashion in rows and columns. Pandas DataFrame consists of three principal components, the data, rows, and columns.

Pandas DataFrame will be created by loading the datasets from existing MS Excel files, CSV files or SQL Database. Pandas DataFrame can also be created from the lists, dictionaries etc.

## Use Pandas to display the dataset
"""

import pandas as pd

#read excel file
train_data_raw = pd.read_excel("/content/PRO-C114-Text-Sentiment-Dataset/text-emotion-training-dataset.xlsx")

#display first five entries of training dataset
train_data_raw.head()

"""## Split the rows in two columns as Text and Emotions"""

#Split the rows in two columns as Text and Emotions
train_data = pd.DataFrame(train_data_raw["Text_Emotion"].str.split(";",1).tolist(), 
                                                     columns = ['Text','Emotion'])

train_data.head()

"""## Giving labels to Emotions"""

#Find unique emotions
train_data["Emotion"].unique()

#Create a Dictionary to replace emotions with labels
encode_emotions = {"anger": 0, "fear": 1, "joy": 2, "love": 3, "sadness": 4, "surprise": 5}

train_data.replace(encode_emotions, inplace = True)
train_data.head()

"""## Convert Dataframe to list of dataset"""

# Convert Dataframe to list of dataset

training_sentences = []
training_labels = []

# append text and emotions in the list using the 'loc' method

for i in range(len(train_data)):
  
  sentence = train_data.loc[i, "Text"]
  training_sentences.append(sentence)

  label = train_data.loc[i, "Emotion"]
  training_labels.append(label)

#Check a random text and label of the list

training_sentences[50], training_labels[50]

"""## Tokenization & Padding

The act of converting text into numbers is known as **Tokenization**. The **Tokenizer** class of Keras is used for encoding text input into integer sequence. 
"""

#import Tokenizer from tensorflow

import tensorflow as tf

from tensorflow.keras.preprocessing.text import Tokenizer

#Define parameters for Tokenizer

vocab_size = 10000
embedding_dim = 16
oov_tok = "<OOV>"
training_size = 20000

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(training_sentences)

#Create a word_index dictionary

word_index = tokenizer.word_index

#Check numeral value assigned to a word

word_index["the"]

training_sequences = tokenizer.texts_to_sequences(training_sentences)

training_sequences[0:2]

"""**Padding** It is important to make all the sentences contain the same number of words. Zero is used for padding the tokenized sequence to make text contain the same number of tokens. """

#Define parameters for pad_sequences

from tensorflow.keras.preprocessing.sequence import pad_sequences

padding_type='post'
max_length = 100
trunc_type='post'


training_padded = pad_sequences(training_sequences, maxlen=max_length, 
                                padding=padding_type, truncating=trunc_type)

training_padded

"""## Converting padded sequences and labels into an Numpy array

"""

#Create numpy arrays for padded sequences and labels
import numpy as np
training_padded=np.array(training_padded)
training_labels=np.array(training_labels)

"""## Model Compilation"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D

model = tf.keras.Sequential([
        Embedding(vocab_size, embedding_dim, input_length=max_length),
        Dropout(0.2),

        Conv1D(filters = 256, kernel_size = 3, activation = "relu"),
        MaxPooling1D(pool_size = 3),

        Conv1D(filters = 128, kernel_size = 3, activation = "relu"),
        MaxPooling1D(pool_size = 3),

        LSTM(128),

        Dense(128, activation = "relu"),
        Dropout(0.2),
        Dense(64, activation = "relu"),
        Dense(6, activation = "softmax")])

model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""## Model Summary"""

#use the summary() method 
model.summary()

"""## Train Model"""

#use the fit() function for training model
num_epochs=30
history=model.fit(training_padded,training_labels,epochs=num_epochs,verbose=2)

"""## Save Model"""

#use the save() method
model.save("text_emotion.h5")

"""## Test the model"""

#use the predict() method for model prediction
sentence=["I am Happy to meet my friend. We are Planning to go to the party","I had a bad day at school. I got hurt while playing football"]
sequence=tokenizer.texts_to_sequences(sentence)
padded=pad_sequences(sequence,maxlen=max_length,padding=padding_type,truncating=trunc_type)
result=model.predict(padded)
predict_class=np.argmax(result,axis=1)
predict_class